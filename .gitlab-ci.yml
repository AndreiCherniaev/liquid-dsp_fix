# gitlab ci/cd pipeline configuration
image: debian

stages:
  - build
  - test

variables:
  DEBIAN_FRONTEND: noninteractive

before_script:
  - apt-get -qq update
  - apt-get -qq install -y --no-install-recommends build-essential cmake valgrind time curl

# build main library and run test programs
build:
  stage: build
  script:
    - rm -rf build
    - mkdir build
    - cd build
    - cmake -DBUILD_AUTOTESTS=ON -DBUILD_BENCHMARKS=ON -DBUILD_EXAMPLES=ON -DBUILD_SANDBOX=ON -DCOVERAGE=OFF ..
    - make -j4
    - ./benchmark -q -o benchmark.json -t 0.01
    - ./xautotest -q -o autotest.json
    #- make check-doc # compile and run documenation checks (e.g. example code in README.md)
    - make install
    - ldconfig
    - cd ..
    - make -f scripts/liquid_linker_test.mk
  artifacts:
    paths:
      - build/benchmark.json
      - build/autotest.json

# generate coverage report and push to codecov.io
coverage:
  stage: test
  script:
    - rm -rf build
    - mkdir build
    - cd build
    - cmake -DBUILD_AUTOTESTS=ON -DBUILD_BENCHMARKS=OFF -DBUILD_EXAMPLES=OFF -DBUILD_SANDBOX=OFF -DCOVERAGE=ON ..
    - make -j4
    - ./xautotest -q -o autotest.json
    - cd ..
    - apt-get -qq install -y --no-install-recommends virtualenv
    - virtualenv coverage
    - source coverage/bin/activate
    - pip install codecov-cli gcovr==7.0
    - gcovr --version
    - gcovr --filter="src/.*/src/.*.c" --print-summary | tee coverage.out
    - codecovcli --version
    - codecovcli upload-process -t $CODECOV_TOKEN --git-service gitlab --slug jgaeddert/liquid-dsp
  coverage: '/lines: \d+\.\d+%/'
  artifacts:
    paths:
      - coverage.out
      - build/autotest.json

# compile and run all example programs, timing how long each takes to run
.examples:
  stage: test
  script:
    - make -j4 examples
    - echo '' > time.txt
    - ls examples/*_example | sed -E "s#(.*)#echo '\1' >> time.txt; { time -p ./\1 ; } 2>> time.txt#g" > run_examples.sh
    - /bin/sh run_examples.sh
  artifacts:
    paths: [run_examples.sh, time.txt]

# compile and run all autotest programs with valgrind
.autotest-memcheck:
  stage: test
  script:
    - make -j4 xautotest
    - mkdir valgrind
    - ./scripts/valgrind_eval.py -output valgrind -test 881
  artifacts:
    paths: [valgrind/*]

